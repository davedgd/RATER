{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/RATER-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4564004-7be7-4b36-a0a8-d700944d837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import janitor\n",
    "\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, TextClassificationPipeline\n",
    "\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f710b-0824-4ac1-9720-263701b9fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from transformers import set_seed\n",
    "seed = 123\n",
    "\n",
    "set_seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d05e2-2d0f-4640-92e0-9815e7439a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name_or_path = 'microsoft/deberta-v3-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cab2ea-3a5d-409a-baee-0d0e88760ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel('data/processed/train_val_test.xlsx', sheet_name = 'train')[['definition', 'ItemText', 'Target']].clean_names()\n",
    "val =   pd.read_excel('data/processed/train_val_test.xlsx', sheet_name = 'val')[['definition', 'ItemText', 'Target']].clean_names()\n",
    "test =  pd.read_excel('data/processed/train_val_test.xlsx', sheet_name = 'test')[['definition', 'ItemText', 'Target']].clean_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d4585-54dd-4f38-ac0c-21035f494b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing only\n",
    "#train = train.sample(n = 1000, random_state = seed)\n",
    "#val =     val.sample(n = 1000, random_state = seed)\n",
    "#test =   test.sample(n = 1000, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7965f01-b9f0-4add-8140-25663e62950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4a57d-9751-4890-9008-88646a738d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.groupby('target').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adec05-dd27-495c-b912-ad0603a0750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_dict({'text_a': train.definition, \n",
    "                              'text_b': train.itemtext, \n",
    "                              'labels': train.target})\n",
    "\n",
    "ds_val = Dataset.from_dict({'text_a': val.definition, \n",
    "                            'text_b': val.itemtext, \n",
    "                            'labels': val.target})\n",
    "\n",
    "ds_test = Dataset.from_dict({'text_a': test.definition, \n",
    "                             'text_b': test.itemtext, \n",
    "                             'labels': test.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fcf872-cfd8-460e-b472-29f8e4556c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': ds_train, \n",
    "    'val': ds_val, \n",
    "    'test': ds_test\n",
    "})\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7cb33-8880-4c68-95a6-60fd8a45f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6284c8-3e70-4ae8-9bc5-3218b6eb095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc0444-76b0-46d0-b253-367825555abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode (examples):\n",
    "    tokenized_examples = tokenizer(examples['text_a'], examples['text_b'], return_token_type_ids = True)\n",
    "    tokenized_examples['labels'] = [int(label) for label in examples['labels']]\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272075a-8bd2-4e77-a909-f3d8682057e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict_tokenized = dataset_dict.map(\n",
    "    encode,\n",
    "    batched = True,\n",
    "    num_proc = os.cpu_count(),\n",
    "    remove_columns = ['text_a', 'text_b']\n",
    ")\n",
    "dataset_dict_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c615b4a-99f8-4456-aa55-e2633e8fa61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer, padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2ac88-aadb-4b38-98ad-54f10a3232e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init ():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        pretrained_model_name_or_path, \n",
    "        num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739e0cb3-ff37-468e-8547-362ca26776c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_hp_space (trial):\n",
    "    return {\n",
    "        'project': 'CV1',\n",
    "        'method': 'grid',\n",
    "        'metric': {'name': 'objective', 'goal': 'maximize'},\n",
    "        'parameters': {\n",
    "            'learning_rate': {'values': [1e-5, 3e-5, 5e-5]},\n",
    "            'per_device_train_batch_size': {'values': [8]},\n",
    "            'num_train_epochs': {'values': [1, 2, 3, 5, 10]}\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d3c03-5a4e-4e42-b1ff-caa00ea7fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics (eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    probs = softmax(predictions, axis = -1)[:, 1]\n",
    "    return {'auc': roc_auc_score(labels, probs)}\n",
    "\n",
    "def tune_for_auc (metrics):\n",
    "    return metrics['eval_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dc5cb-ae2c-46da-b914-be47c02c1c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    'content_validity',\n",
    "    per_device_eval_batch_size = 32,\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy = 'no'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    args = args,\n",
    "    data_collator = data_collator,\n",
    "    model_init = model_init,\n",
    "    train_dataset = dataset_dict_tokenized['train'],\n",
    "    eval_dataset = dataset_dict_tokenized['val'],\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb81ca-0520-484f-ba0c-dcfa9df903f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = trainer.hyperparameter_search(\n",
    "    direction = 'maximize',\n",
    "    backend = 'wandb',\n",
    "    hp_space = wandb_hp_space,\n",
    "    compute_objective = tune_for_auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a112e5e1-2c12-4467-9941-1b956e5f7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889eeb8e-3300-4f6b-af22-982849a77c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b46656-d596-431e-a174-6c8dcf382779",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_settings_df = pd.DataFrame({\n",
    "    'model': pretrained_model_name_or_path,\n",
    "    'learning_rate': best_trial.hyperparameters['learning_rate'],\n",
    "    'per_device_train_batch_size': best_trial.hyperparameters['per_device_train_batch_size'],\n",
    "    'num_train_epochs': best_trial.hyperparameters['num_train_epochs']\n",
    "}, index = [0])\n",
    "best_settings_df.to_csv('results/' + pretrained_model_name_or_path.replace('/', '_') + '_hyperparams.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e09b69d-63d4-4114-8b00-ee70e8c7e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit model using manual settings via True; otherwise, False\n",
    "if False:\n",
    "    best_trial = lambda: None\n",
    "    best_trial.hyperparameters = {\n",
    "        'learning_rate': 1e-05,\n",
    "        'per_device_train_batch_size': 8,\n",
    "        'num_train_epochs': 1\n",
    "    }\n",
    "\n",
    "best_trial.hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e260ee-186d-4d91-93ff-7f697d00c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_args = TrainingArguments(\n",
    "    'content_validity',\n",
    "    learning_rate = best_trial.hyperparameters['learning_rate'],\n",
    "    per_device_train_batch_size = best_trial.hyperparameters['per_device_train_batch_size'],\n",
    "    num_train_epochs = best_trial.hyperparameters['num_train_epochs'],\n",
    "    per_device_eval_batch_size = 32,\n",
    "    eval_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "    report_to = 'none'\n",
    ")\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    args = final_args,\n",
    "    data_collator = data_collator,\n",
    "    model_init = model_init,\n",
    "    train_dataset = dataset_dict_tokenized['train'],\n",
    "    eval_dataset = dataset_dict_tokenized['val'],\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99361d-3c35-4d8a-a057-4ce87348e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'models/' + pretrained_model_name_or_path.replace('/', '_')\n",
    "final_trainer.train()\n",
    "final_trainer.save_model(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c860863-21a2-4112-8290-37811815a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_dict = []\n",
    "\n",
    "for i, _ in test.iterrows():\n",
    "    data_test_dict.append({'text': test['definition'][i], \n",
    "                           'text_pair': test['itemtext'][i]})\n",
    "\n",
    "data_test_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fd8de4-d98b-4778-a1f8-51d8eeaeb9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels = 2\n",
    ").to(device)\n",
    "\n",
    "pipe = TextClassificationPipeline(model = model, tokenizer = tokenizer, top_k = None, device = device)\n",
    "\n",
    "# temporary workaround for XLNet batch size issue\n",
    "if str(model.base_model).find('XLNetModel') != -1:\n",
    "    batch_size = 1\n",
    "else:\n",
    "    batch_size = 128\n",
    "\n",
    "raw_probs = pipe(data_test_dict, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5981c-7905-43ed-b841-e5f675fab066",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.array([item[['LABEL_1' == i['label'] for i in item].index(True)]['score'] for item in raw_probs])\n",
    "preds = np.where(probs >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2471d86-8459-416b-beb2-463aefb4e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({\n",
    "    'definition': test['definition'],\n",
    "    'itemtext': test['itemtext'],\n",
    "    'target': test['target'],\n",
    "    'prob': probs\n",
    "})\n",
    "\n",
    "out.to_csv('results/' + pretrained_model_name_or_path.replace('/', '_') + '_preds.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ht",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
